---
title: "Heterogeneous Data Registration for 3D Underwater Scene Reconstruction"
collection: publications
permalink: /publication/2018-heterogeneous
excerpt: ''
date: 2018-09-22
venue: 'Proc. MTS/IEEE OCEANS'
paperurl: 'https://ieeexplore.ieee.org/abstract/document/8232327'
citation: 'T. H. Nguyen, D. Guériot, J.-M. Le Caillec., C. Sintès and S. Daniel (2017). &quot;Heterogeneous Data Registration for 3D Underwater Scene Reconstruction.&quot; <i>Proceedings of the MTS/IEEE OCEANS 2017 - Anchorage</i>. 1(3).'
---

**Abstract:** Applications based on synergistic integration of optical imagery and LiDAR data are receiving a growing interest from the remote sensing community. However, a misaligned integration between these datasets may fail to fully profit the potential of both sensors. In this regard, an optimum fusion of optical imagery and LiDAR data requires an accurate registration. This is a complex problem since a versatile solution is still missing, especially when considering the context where data are collected at different times, from different platforms, under different acquisition configurations. This paper presents a coarse-to-fine registration method of aerial/satellite optical imagery with airborne LiDAR data acquired in such context. Firstly, a coarse registration involves extracting and matching of buildings from LiDAR data and optical imagery. Then, a Mutual Information-based fine registration is carried out. It involves a super-resolution approach applied to LiDAR data, and a local approach of transformation model estimation. The proposed method succeeds at overcoming the challenges associated with the aforementioned difficult context. Considering the experimented airborne LiDAR (2011) and orthorectified aerial imagery (2016) datasets, their spatial shift is reduced by 48.15% after the proposed coarse registration. Moreover, the incompatibility of size and spatial resolution is addressed by the mentioned super-resolution. Finally, a high accuracy of dataset alignment is also achieved, highlighted by a 40-cm error based on a check-point assessment and a 64-cm error based on a check-pair-line assessment. These promising results enable further research for a complete versatile fusion methodology between airborne LiDAR and optical imagery data in this challenging context.

**Keywords:** airborne LiDAR, optical imagery, aerial imagery, satellite imagery, registration, heterogeneous sensors, coarse-to-fine, building extraction, super-resolution, mutual information, urban scenes.

The preprint can be downloaded from [arXiv](https://arxiv.org/abs/1909.13817).
